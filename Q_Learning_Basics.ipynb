{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vey27/Reinforcement-Learning/blob/main/Q_Learning_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMvqYyyfrHNc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iugPadHarQAV"
      },
      "source": [
        "#Setting rewards in the environment. Coded by Simulator Designer\n",
        "\n",
        "# Goal --- 100 points\n",
        "# Correct door = 0 point\n",
        "# Reaching Wrong Door = -1 point\n",
        "rewards=np.array([\n",
        "                  [-1,-1,-1,-1,0,-1],\n",
        "                  [-1,-1,-1,0,-1,100],\n",
        "                  [-1,-1,-1,0,-1,-1],\n",
        "                  [-1,0,0,-1,0,-1],\n",
        "                  [0,-1,-1,0,-1,-1],\n",
        "                  [-1,0,-1,-1,-1,-1]\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpiY3iMVr2x4",
        "outputId": "5c300441-97b3-46da-b9e4-ca5752ae9f21"
      },
      "source": [
        "rewards"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -1,  -1,  -1,  -1,   0,  -1],\n",
              "       [ -1,  -1,  -1,   0,  -1, 100],\n",
              "       [ -1,  -1,  -1,   0,  -1,  -1],\n",
              "       [ -1,   0,   0,  -1,   0,  -1],\n",
              "       [  0,  -1,  -1,   0,  -1,  -1],\n",
              "       [ -1,   0,  -1,  -1,  -1,  -1]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7TjgZEer4Oi"
      },
      "source": [
        "#This function is coded by RL engineer with an intention to initialize the Q Table\n",
        "# Here m is no of state and n is no of actions\n",
        "def initialize_q(m,n):\n",
        "  return np.zeros((m,n))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJWWa1X_xV30",
        "outputId": "b431682b-f813-4851-bcee-5604cd2aed51"
      },
      "source": [
        "q_matrix = initialize_q(6,6)\n",
        "\n",
        "q_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TxsmPENsGk-"
      },
      "source": [
        "#Coded by Design Team/ Coded by Simulator Designer\n",
        "def set_initial_state(rooms=6):\n",
        "  #set the initial state like env.reset()\n",
        "  return np.random.randint(0,rooms)\n",
        "  #return 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul1n8tMHsaEe"
      },
      "source": [
        "#Done by the Design Team /  Coded by Simulator Designer\n",
        "# Indirectly this is Exploration Code\n",
        "\n",
        "def get_action(current_state, reward_matrix):\n",
        "  #Given a state choose the possible actions\n",
        "  valid_actions =[]\n",
        "  for action in enumerate(reward_matrix[current_state]):\n",
        "    if action[1] != -1:\n",
        "      valid_actions += [action[0]]\n",
        "\n",
        "  return random.choice(valid_actions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYOATOtos39-"
      },
      "source": [
        "#Coded by RL\n",
        "# Similar to env.step()\n",
        "# Applying Q Learning Algo\n",
        "def take_action(current_state, reward_matrix, gamma, verbose=False):\n",
        "  #Take Single action\n",
        "  action = get_action(current_state, reward_matrix)\n",
        "  sa_reward = reward_matrix[current_state,action] #current state-action reward\n",
        "  ns_reward = max(q_matrix[action,]) #next state action reward\n",
        "  #print(ns_reward)\n",
        "\n",
        "  q_current_state = sa_reward + (gamma * ns_reward)\n",
        "  q_matrix[current_state,action] = q_current_state #Update Q Matrix\n",
        "\n",
        "\n",
        "  new_state = action\n",
        "\n",
        "  if verbose:\n",
        "    print(pd.DataFrame(q_matrix))\n",
        "    print(f\"Old State: {current_state} | New State: {new_state}\\n\\n\")\n",
        "    if new_state==5:\n",
        "      print(f\"Agent has reached his Goal!\")\n",
        "\n",
        "  return new_state\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMgv9DBkubSn"
      },
      "source": [
        "#Help you run one episode\n",
        "def initialize_episode(reward_matrix, initial_state, gamma, verbose=False):\n",
        "  #Runs one episode  until agent reaches its goal state\n",
        "  current_state = initial_state\n",
        "  while True:\n",
        "    current_state = take_action(current_state, reward_matrix, gamma, verbose)\n",
        "    if current_state==5:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTHz_SRCu49f"
      },
      "source": [
        "# Help you run several episodes defined in iterations\n",
        "def train_agent(iterations, reward_matrix, gamma, verbose=False):\n",
        "  #Runs given number of episodes\n",
        "  print(\"Training in progress ...\")\n",
        "\n",
        "  for episodes in range(iterations):\n",
        "    initial_state=set_initial_state()\n",
        "    initialize_episode(reward_matrix, initial_state, gamma, verbose)\n",
        "\n",
        "  print(\"Training complete !\")\n",
        "\n",
        "  return q_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ6bTTPXvWkk"
      },
      "source": [
        "def normalize_matrix(q_matrix):\n",
        "  normalized_q = q_matrix / max(q_matrix[q_matrix.nonzero()]) * 100\n",
        "  return normalized_q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sgGbn5tv5EI",
        "outputId": "ef32fc05-44ac-4a9b-ee47-b7116b90e2ba"
      },
      "source": [
        "#Test Run\n",
        "\n",
        "gamma = 0.8\n",
        "initial_state = set_initial_state()\n",
        "#print(initial_state)\n",
        "initial_action =  get_action(current_state=initial_state, reward_matrix=rewards)\n",
        "initialize_episode(rewards,initial_state, gamma , True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 1 | New State: 3\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 3 | New State: 1\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 1 | New State: 3\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 3 | New State: 4\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 4 | New State: 3\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 3 | New State: 1\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 1 | New State: 3\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 3 | New State: 4\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 4 | New State: 3\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 3 | New State: 4\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 4 | New State: 3\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 3 | New State: 2\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 2 | New State: 3\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 3 | New State: 4\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 4 | New State: 0\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 0 | New State: 4\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 4 | New State: 3\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 3 | New State: 1\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 1 | New State: 3\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 3 | New State: 2\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 2 | New State: 3\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 3 | New State: 2\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 2 | New State: 3\n",
            "\n",
            "\n",
            "     0    1    2    3    4    5\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "Old State: 3 | New State: 1\n",
            "\n",
            "\n",
            "     0    1    2    3    4      5\n",
            "0  0.0  0.0  0.0  0.0  0.0    0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  100.0\n",
            "2  0.0  0.0  0.0  0.0  0.0    0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0    0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0    0.0\n",
            "5  0.0  0.0  0.0  0.0  0.0    0.0\n",
            "Old State: 1 | New State: 5\n",
            "\n",
            "\n",
            "Agent has reached his Goal!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "Z8mXNP9nwR7D",
        "outputId": "dda8e8ab-3eac-485c-9a8c-9f88954ef3a7"
      },
      "source": [
        "# Test Run for full training ( 2000 iterations)\n",
        "\n",
        "initial_state = set_initial_state()\n",
        "initial_action =  get_action(current_state=initial_state, reward_matrix=rewards)\n",
        "q_table = train_agent(2000, rewards, gamma, False)\n",
        "\n",
        "pd.DataFrame(q_table)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training in progress ...\n",
            "Training complete !\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>142.222222</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>177.777778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>277.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>177.777778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>222.222222</td>\n",
              "      <td>142.222222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>142.222222</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>113.777778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>177.777778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>222.222222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0           1           2           3           4           5\n",
              "0    0.000000    0.000000    0.000000    0.000000  142.222222    0.000000\n",
              "1    0.000000    0.000000    0.000000  177.777778    0.000000  277.777778\n",
              "2    0.000000    0.000000    0.000000  177.777778    0.000000    0.000000\n",
              "3    0.000000  222.222222  142.222222    0.000000  142.222222    0.000000\n",
              "4  113.777778    0.000000    0.000000  177.777778    0.000000    0.000000\n",
              "5    0.000000  222.222222    0.000000    0.000000    0.000000    0.000000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4yG8zDdyo97"
      },
      "source": [
        "def deploy_agent(init_state, q_table):\n",
        "  print(\"Start: \", init_state)\n",
        "  state=init_state\n",
        "  steps=0\n",
        "  while True:\n",
        "    steps+=1\n",
        "    action = np.argmax(q_table[state,:])\n",
        "    print(action)\n",
        "    state=action\n",
        "    if action==5:\n",
        "      print(\"Finished!\")\n",
        "      return steps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHX3VgpSzGEI",
        "outputId": "b78aaffe-ed23-4188-b18f-9d9c507572b1"
      },
      "source": [
        "start_room = 2\n",
        "steps = deploy_agent(start_room,q_table)\n",
        "print(\"number of rooms/actions: \",steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start:  2\n",
            "3\n",
            "1\n",
            "5\n",
            "Finished!\n",
            "number of rooms/actions:  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO0TiBJQzv_X"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}